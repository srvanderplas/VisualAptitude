---
title: "Summary of Changes"
author: "Susan VanderPlas & Heike Hofmann"
output: word_document
---

# Major Concerns
1. **Are all the experimental design choices properly motivated?**    
**(refer to the first concern of R1).**    
*The purpose of each of the cognitive tests is described in section 2.2. In summary, the paper-folding, card rotation, and figure classification tasks are part of the kit of factor-referenced cognitive tests (and are thus extremely well-studied); additionally, the authors chose the specific visual searching task (VST) because of its similarity of form to statistical lineups and its' compatibility with the written form of the other cognitive tests and lineup tests.*    
*As mentioned in the paper, the paper folding and card rotation tests have been used in many previous studies of statistical graphics and data displays. The figure-classification task examines inductive reasoning, which is another component of the lineup task (determining the dimension on which the lineup components differ, then applying that to answer the question successfully).*
2. **Are the experimental procedure sufficiently detailed?**    
**(refer to the second concern of R1 and )**    
*We have added additional detail about the experimental procedures, and have included the testing materials as supplementary documents (with the factor-referenced kit tests redacted due to copyright issues; in these cases only the instruction page is shown). The testing documents are comprehensive, and oral instructions mirror the instructions on the introduction page of each task (students are familiar with this format as it is commonly used on standardized tests, such as the SAT and ACT).*
3. **The results of statistical analysis do not seem to be conclusive, are the interpretations of these results properly revised?**    
**(refer to the third concern of R1)**    
*The results of the statistical analysis are as conclusive as the nature of the study allows. While correlations of 0.3-0.4 are low compared to the absolute range of 0 - 1, they are strong for human subjects data (which is how we have interpreted them here). Because so many different factors influence human behavior, we generally do not see correlations above 0.5 on distinct tasks.*
*We have provided both graphics and PCA results in order to demonstrate our results in more than one way; while these results are preliminary, the cost involved in designing and executing a study which would enable multivariate hypothesis testing (given the multiple correlations between dependent variables) is prohibitive. This study is the first to examine the visual and cognitive skills necessary to evaluate statistical lineups; follow-up studies may provide more statistically precise results.*
4. **Does the revision contain additional discussion of why PCA is a proper approach to interpret the data for the VIS community members who do not have sufficient statistics background?**    
**(refer to the concern of R2)**    
*The revision includes a reference to a PCA tutorial (for those unfamiliar with the procedure) and explains the rationale for utilizing PCA in some additional detail. Section 3.3 - Visual Abilities and Lineup Performance has been modified extensively to provide additional details about PCA.* 
5. **Does the revision has the clear description of "most different"?**    
**(refer to the first concern of R3)**    
*The use of 'most different' is a feature of the lineup protocol, and does not bias the participants to examine specific distributional characteristics. While participants may choose different distributional features to identify the 'most different' plot, this mirrors how we perceive graphics (we cue in to different features). In addition, many statistical tests react to different features of the data - a t-test may not produce significant results even with a truly significant difference in means if the two distributions have wildly different variances. Finally, the use of 'most different' allows the lineup protocol to be used even in populations which do not have mathematical training and might not understand the use of terms such as mean and variance.*
*We have added additional language in Section 2.1 to emphasize that the phrasing is a standard part of the lineup protocol.*
6. **Does the revision has the proper discussion of visualization design**    
**(refer to the second concern of R3)**    
*This study was not designed to directly impact visualization design recommendations. While the lineup protocol can easily be used to compare many different visualization designs, the goal of this experiment was to examine the cognitive requirements of lineup evaluation at the participant level. As such, it would not be appropriate to discuss visualization design in detail.*
*While there are differences in the correlation of scores on lineup sets 1, 2, and 3 with the cognitive tests, this does not provide any additional information about whether designs in lineup set 1 are superior to those in lineup set 2 and lineup set 3, and in fact, the sets of lineups are not comparable in this way. Each set of lineups was taken from an experiment which did aim to rank designs by effectiveness, but in this study we are instead examining individual differences in cognitive abilities and lineup performance.*
7. **Does the revision resolve a potential concern of confounding factors**    
**(refer to the conern of R3)**    
*The issue of confounding factors is related to the issue raised in #6, that is, that we have not discussed visualization design in this paper. As explained above, our goal was not to compare types of visualizations, but rather to examine individual differences in cognitive abilities and performance on lineup tasks. The tasks which underlie each set of lineups (as described in the caption of Fig. 2 in the revision) are common tasks in statistical graphics. In addition, the similarity in test protocol between the VST, the tests from the factor-referenced kit of cognitive tests, and the lineup protocol was intentional; by controlling the experimental protocol, we could reduce participant confusion and the corresponding variability. As our goal was not to examine the elements of visualization design experimentally, controlling those elements is one element of appropriate experimental design.*
8. **Does the revision have an explicit related works section?**    
**(refer to the last concern of R3)**    
*An explicit related works section has been added at the conclusion of Sec. 1.*
9. **Does the revision handle all the minor issues raised by reviewers?**

# Minor Issues
**Minor issues raised by Reviewer 1:**

- In 2.2, Wolfe’s work on visual search should be mentioned in relation to the VST.    
*A citation has been added, but Wolfe's work on visual search differs from the VST used in this study; while the underlying cognitive mechanisms may be the same, a detailed explanation of the feature integration component of visual search seems extraneous to the study described in this paper.*
- Equation (2) states the same as equation (1).    
*The repetition has been removed due to space constraints.*
- In section 3, you mention one exception in relation to the participants’ age, please be more specific.    
*This wording has been modified to provide more detail*
- In section 3, I suppose you mean that the demographics are representative for the student population and not for the whole university incl staff.    
*Indeed, though the wording has been modified for clarity in the revised draft.*
- With regard to your assessment of the correlation in Fig 6. I would discriminate more between the individual results rather than stating that they are all highly correlated.    
*Additional wording has been added to this effect.* 
- It would be good to move Table 1 to the previous page.    
*Due to LaTeX's float placement, it is difficult to place a figure/table which spans two columns on the same page as a lone single-column figure. Table 1 is as close to Section 3.1 as is possible given these constraints.*
- Concerning Fig 5: I am not surprised that there is no difference for age, as the difference is minimal and the groups would probably be put into the same group would there be a wider spread of age in the participant population.    
*Absolutely; however, even in pilot studies (in populations with more age variability) there did not seem to be a difference due to age in lineup evaluations. Age was included as a demographic variable, but we did not expect there to be significant differences due to age.*
- In the last paragraph of section 3.3: There is a typo “… is ultimately are a classification…”.    
*This has been resolved in the revised draft.*
- Beginning of 3.4: you mention that all demographic variables are highly correlated. Really all? Please be more specific.    
*This has been re-phrased.*
- Task for lineup 3 is given. What were the tasks given for the evaluation of lineups 1 and 2?    
*We are not sure what part of the paper you're referencing here; we have added additional information about lineup set 1 and 2 at the beginning of Section 3.5 for clarity.*
- The VST task is excluded from Fig 10 due to its low correlation. Please include it for completeness.    
*Fig. 10 has been modified accordingly.*
- PCA is explained in detail in 3.5 although it has been used extensively earlier. Please put the explanation before the first use.    
*The description of PCA in Sec. 3.5 is specifically focused on the development of Fig. 11, which is not a traditional plot used to display PCA data. Additional detail about PCA has been added earlier in the paper, but the development of the influence plot remains in Sec. 3.5 as well.*
- Section 4: I don’t agree with the initial statement that lineups are strongly related to the performance on tests of visual ability. There is certainly evidence provided for that in the paper, but I would not refer to it as strong evidence.    
*We have added additional language to clarify that 'strong' here is relative to other human subjects data, which typically is more variable and thus has lower correlations than data from other scientific pursuits.*
- I propose to put Appendix C into the main body of the paper.    
*Due to space constraints, Appendix C does not fit in the main body of the paper. Additionally, due to small sample sizes, more work is required to draw any strong conclusions from the analysis in Appendix C. Analyzing the correlations on the individual plot design level would be an interesting follow up study (and thus, we have provided an initial analysis as an appendix).*
- In Appendix C: I don’t agree with the statement that the card rotation task is much more associated with the QQ plots. The correlations are actually higher for the first four plot types on the left in the figure.    
*This statement has been modified for clarity.*

**Minor issues raised by Reviewer 2:**

- page 2 “speed[9]”: Put a space right before a citation throughout this paper.    
*This change has been made throughout.*
- page 3 “Lineups require similar manipulations in two-dimensional space, and also require the ability to perform complex spatial manipulations mentally; for instance, comparing the interquartile range of two box- plots as well as their relative alignment to a similar set of two boxplots in another panel.”    
I understand that the experiment follows the line-up protocols, but it is unclear how it was conducted in detail. What are the visualizations used for the three blocks of 20 lineups. What are tasks? (Task examples are shown in Figure 1(a), but not sure if the same task was used for all lineups). I later found that more examples of line-up tasks are described in Section 3.6, but the detailed descriptions of tasks are still necessary.    
*The additional detail provided in the caption of Fig. 2 addresses this; we have also included the test documents to provide more detail and facilitate replication of this experiment. In addition, we have moved the figure in Section 3.6 to the methods section so that this part of the experimental design is clear from the beginning.*
- page 6 “3.5 Lineup Types”: This should be go to the Methods section, not the result section.    
*The analysis has remained in section 3.5, but the title has been modified for clarity. The figure with all of the lineup types has also been moved to the methods section.*

**Minor issues raised by Reviewer 3:**

- Additional experimental details about the type of visualizations tested (e.g. Figure 9) should be presented in the Methods section. A pointer to another set of papers with large numbers of potential designs is insufficient to understand the experiment.    
*Some additional detail has been added, but we have also included the test documents as supplementary material; they are designed to provide all of the instructions a participant would need to complete the experiment (much as standardized tests are designed to require relatively little instruction outside of the test booklet).*
- Additionally, explanations of the baseline cognitive tests should be presented up front to ground the analysis: while many in the visualization community may have seen the compared tests (visual search task (VST), paper folding test, card rotation test, and figure classification test), especially the visual search task, many other have not. Give the necessary grounding and explain why these particular tasks were chosen as a baseline.    
*Some additional justification of the cognitive tests has been added, but many of these tests are commonly used in studies of statistical graphics and cognition (and those studies have been cited in the test description section). The visual search task (VST) has not been previously used in statistical graphics, but the justification for using this form of visual search task is provided in Section 2.2.*
- Throughout the paper, the term “graphics” is used instead of “visualization”. “Graphics” has a much broader possible meaning and “visualization” is conventional for the InfoVis audience.    
*Visualization is a much broader term than ``statistical graphics'', but we have attempted to clarify the use of the term graphics as much as possible.*
- speed[9] -> speed [9] reasoning[6] -> reasoning [6]    
*This change has been made throughout the paper.*

**Minor issues raised by Reviewer 4:**

- I’d suggest a mention of the groundbreaking mental rotation research of Shepard & Metzler. This was 3D rotation, but it did stimulate thinking by later psychologists on the rotation problem. What’s more, their results were confirmed by subsequent neurological research in Science magazine.    
*We have cited the canonical Shepard & Metzler paper, but as graphics are typically two-dimensional we did not utilize the three-dimensional rotation task from the Kit of Factor Referenced Cognitive Tests. This would be an interesting addition to future studies.*
