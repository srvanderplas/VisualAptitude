\documentclass{article}
%---------------------------------------------------
\usepackage{color}
\usepackage{fullpage}
\usepackage[dvipsnames,svgnames]{xcolor}
\usepackage{wrapfig,float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{url}
\usepackage{ulem}
\usepackage[section]{placeins}
\usepackage{sidecap}
\usepackage{multirow}
\usepackage{bbm}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{rotating}

% Bibliography without numbers or labels
\usepackage{natbib}
\bibliographystyle{apa}

%Optional Package to add PDF bookmarks and hypertext links
\usepackage[pdftex,hypertexnames=false,linktocpage=true]{hyperref}
\hypersetup{colorlinks=true,linkcolor=blue,anchorcolor=blue,citecolor=blue,filecolor=blue,urlcolor=blue,bookmarksnumbered=true,pdfview=FitB}
%---------------------------------------------------

%---------------------------------------------------
%                 Editing Commands
\newcommand{\done}[2][inline]{\todo[color=SpringGreen, #1]{#2}}  % for todos that have been seen and dealt with
\newcommand{\meh}[2][inline]{\todo[color=White, #1]{#2}}   % for todos that may no longer be relevant 
\newcommand{\comment}[2][inline]{\todo[color=SkyBlue, #1]{#2}} % for comments that may not be "to-do"s
\newcommand{\mcomment}[1]{\todo[color=SkyBlue]{#1}} % for margin comments
\newcommand{\newtext}[1]{\todo[inline, color=White]{ \color{OliveGreen}{#1}}} % new text - not necessarily something to be done
\newcommand{\move}[1]{\todo[inline, color=Lime]{#1}} % new to do item
%
%---------------------------------------------------

%---------------------------------------------------
%             Set Picture Locations
\graphicspath{{Figure/}{Images/}}
%
%---------------------------------------------------

<<VisualAptitude-setup, fig.keep='all', cache=FALSE, echo=FALSE, eval=TRUE>>=
rm(list=ls())
wd <- getwd()

opts_chunk$set(fig.path='Figure/fig-', cache.path='cache/', fig.align='center', fig.width=5, fig.height=5, fig.show='hold', par=TRUE, cache=TRUE, concordance=TRUE, autodep=TRUE, root.dir="../")
datadir <- "../../Data/"
imgdir <- "Figure/"
codedir <- "../../Code/"

options(replace.assign=TRUE,width=70,scipen=3)
require(knitr)

library(reshape2)
suppressMessages(library(ggplot2))
library(plyr)
suppressMessages(library(gridExtra))
source(paste(codedir, "Analysis.R", sep=""))
@

\title{Spatial Reasoning and Statistical Graphics}
\author{Susan VanderPlas, Heike Hofmann} % , Stephanie De Graaf, Hillary Cheney ??

\begin{document}
\maketitle

\section{Introduction}
Relevant literature: 
\begin{itemize}
\item \citet{shah1995conceptual} showed that spatial ability was not correlated with accuracy on a simple two-dimensional line graph description task, but that mathematical ability was correlated with accuracy. 
\item \citet{just1985cognitive} showed that high-spatial-ability viewers used different rotation strategies than low-spatial-ability viewers when asked to whether three-dimensional alphabet cubes were the same. 
\item \citet{hofmann2012graphical} for lineup stimuli and general lineup performance
\end{itemize}

Lineups depend on the ability to search for a signal amid distractors (Visual Search Task) and the ability to infer patterns from stimuli (Pattern Recognition task). Some lineups (polar coords) also depend on the ability to mentally rotate stimuli (spatial rotation task) and mentally manipulate graphs (paper folding task). By breaking the lineup task down into component parts, we can correlate lineup performance with similar cognitive factor tests to determine where additional variation in skill level factors into performance differences. In addition, we can correlate previous experiences (science-based major, research experience, Auto-CAD skills) with performance to explore the effect that participant experience has on lineup performance. 

\section{Methods}
Participants will complete the following tasks (sample pictures included, full stimuli set will be added to the appendix once testing is complete). Tasks are designed so that participants are under time pressure; they are not expected to complete all of the problems in each section. This provides more discrimination between high scorers and prevents score compression at the top of the range. 
\begin{itemize}
\item Visual Search Task: designed to test participants' ability to find a target stimulus in a field of distractors. An example is shown in figure \ref{fig:VST}. 
\begin{figure}[htbp]\centering
\includegraphics[width=.7\textwidth]{VisualSearch}
\caption[Visual Search Task]{Visual Search Task. Participants are instructed to find the plot numbered 1-24 which matches the plot labeled "Target". Participants will complete up to 25 of these tasks in 5 minutes.}\label{fig:VST}
\end{figure}
\item Paper Folding Task: tests participants' ability to visualize and mentally manipulate figures in three dimensions. Associated with the ability to extrapolate symmetry and reflection over multiple steps. An example is shown in figure \ref{fig:paperfolding}.
\begin{figure}[htbp]\centering
\includegraphics[width=.9\textwidth]{paperfolding}
\caption[Paper Folding Task]{Paper Folding Task. Participants are instructed to pick the figure matching the sequence of steps shown in the left-hand figure. Participants will complete up to 20 of these tasks in 6 minutes.}\label{fig:paperfolding}
\end{figure}
\item Card Rotation Task: tests participant's ability to rotate objects in two dimensions to distinguish between left-hand and right-hand versions of the same figure. Tests spatial reasoning ability and mental rotation skills. An example is shown in figure \ref{fig:cardrotation}.
\begin{figure}[htbp]\centering
\includegraphics[width=.9\textwidth]{cardrotation}
\caption[Card Rotation Task]{Card Rotation Task. Participants mark each figure on the right hand side as either the same or different than the figure on the left hand side of the dividing line. Participants will complete up to 20 of these tasks (each consisting of 8 figures) in 6 minutes.}\label{fig:cardrotation}
\end{figure}
\item Figure Classification Task: tests participant's ability to extrapolate rules from provided figures. This task is associated with visual reasoning capabilities and we expect that it should correlate with the ability to pick out a signal plot from a lineup. An example is shown in figure \ref{fig:figureclassification}. 
\begin{figure}[htbp]\centering
\includegraphics[width=.9\textwidth]{figureclassification}
\caption[Figure Classification Task]{Figure Classification Task. Participants classify each figure in the second row as belonging to group 1, 2, or 3 (if applicable). Participants will complete up to 14 of these tasks (each consisting of 8 figures to classify) in 8 minutes.}\label{fig:figureclassification}
\end{figure}
\end{itemize}

Between cognitive tasks, participants will also complete three blocks of 20 lineups each. These lineups have been previously tested \citep{hofmann2012graphical} and include some null lineups (i.e. lineups without a target plot). Participants %will 
have 5 minutes to complete each block of 20 lineups. Figure \ref{fig:lineup} shows a sample lineup of box plots. 

\begin{figure}[htbp]\centering
\includegraphics[width=.9\textwidth]{lineup}
\caption[Sample Lineup]{A sample lineup. Participants are instructed to choose the plot which appears most different from the others. In this lineup, plot 13 is the target. }\label{fig:lineup}
\end{figure}

In addition to these tests, participants will complete a questionnaire which includes questions about colorblindness, mathematical background, self-perceived verbal/mathematical/artistic skills, time spent playing video games, and undergraduate major. These questions are designed to assess different factors which may influence a participant's skill at reading graphs and performing spatial tasks. 

\section{Results}
\newtext{Results are based on an evaluation of \Sexpr{nrow(ans)} undergraduate students at Iowa State University. }
Scoring of all test results was done such that random guessing leads to an expected value of 0; thus for a test consisting of multiple choice questions with $k$ suggested answers with a single correct answer each, the score is calculated as
\begin{eqnarray}\label{eq.scoring}
\# \text{total correct answers } - 1/(k-1) \cdot \# \text{wrong answers}.
\end{eqnarray}
This allows us to compare each participant's score in light of how many problems were attempted as well as the number of correct responses. Combining accuracy and speed into a single number does not only make a comparison of test scores easier,  this scoring mechanism is also used on many standardized tests, such as the SAT and the battery of psychological tests which parts of this test are drawn from \citep{diamond1973correction, ekstrom1976manual}.

Additionally, we have to ensure that the ranges and units of test scores are comparable. Assume $n$ questions with $k$ choices (including one correct answer) each. 
This leads to a theoretical range of $[-n/(k-1), n]$ and, under an additional assumption of random guessing, a variance of 

\begin{eqnarray*}
\text{Var}(X_{n, k}) &=& n^2 \text{Var}(X_{n, k}) = \\
&=& n^2 (\underbrace{1/k \cdot 1^2}_{\text{correct answer}}+ \underbrace{(-1/(k-1))^2 \cdot (k-1)/k}_{\text{wrong answer}}) = \\
&=& n^2/(k-1)
\end{eqnarray*}

\comment{\textit{We might need to expand this a bit to account for the figure classification section, which has some questions with 2 answers and some with 3. Or we could leave it as an exercise for the reader :)}}

\comment{\textit{So are we scaling things by the variance/std dev. under random guessing? Or by the theoretical test range?}\\
Right now, I'm assuming that we're scaling between 0 and 100 by test range $[-a, b]$. So we take the guessing-fixed score and add $a$, then divide by $(a+b)$ and multiply by 100.}

\comment{The next step is an overview of the possible ranges of the test scores in our study, because that is driven by the number of tests shown. It would be good to scale everything, so that we have the same theoretical range. That will actually allow a comparison across different tests.}
<<means>>=
library(plyr)
ldply(ans.summary[,c("lineup","card_rot", "fig_class", "folding", "vis_search")], c(mean=mean,sd= sd))
@

\comment{If test scores have the same ranges, we could include a mini table of means and standard deviations of the four tests, and discuss whether these findings are consistent to how people usually score (except for the females we have about the same population). }

\comment{
Split the next sentence up into two paragraph: what is shown in each of the figures, what are the immediate conclusions? chuck out the gaming hours from figure \ref{fig:visualaptitudects}, that's a demograph, so move it to the other plot (I am aware that nine demographics are easier to display than ten, but content trumps). \\
\textit{Actually, they were split up like that because of continuous vs. categorical. It's not easy to facet when you have different $x$ scales. I've removed video games entirely for the time being. I agree it didn't really belong there, but I can't get it to work with the facetting, either. I will probably just bin it eventually. 
}}

\comment{What happened to the arts skills? I seem to have a positive association now - why is my data different from yours? \\
\textit{I have the same updated results you do. I see that Stephanie changed the data file (but didn't add any more rows)... is it possible something changed there? Otherwise, maybe my dropbox didn't update correctly the first time? Or maybe it was figure caching?}}
Results are presented graphically in figures \ref{fig:visualaptitudects} and \ref{fig:visualaptitudecat}. 

<<VisReasoningAnalysis,echo=FALSE, include=FALSE, fig.width=10,fig.height=5, out.width='\\linewidth'>>=
lineup.summary$variable <- factor(lineup.summary$variable, labels=c("Card Rotation", "Figure Classification", "Paper Folding", "Visual Search"))
 
qplot(data=lineup.summary, x=value, y=lineup, geom="point", shape=I(1), size=I(3)) + facet_wrap(~variable, scales="free_x") + xlab("Scaled Score") + ylab("Scaled Lineup Score") + geom_smooth(method="lm") + theme_bw()
ggsave(paste(imgdir, "fig-VisReasoningAnalysisCts.png", sep=""), width=6, height=4)

lineup.summary.categorical <- rbind(lineup.summary.categorical, data.frame(id=1, lineup=NA, variable="verbal_skills", value=1))
lineup.summary.categorical <- rbind(lineup.summary.categorical, data.frame(id=1, lineup=NA, variable="math_skills", value=1))
lineup.summary.categorical$variable <- factor(lineup.summary.categorical$variable, labels=c("Age", "Sex", "Math/Science Research", "Statistics Class", "Calculus 1", "Verbal Skills", "Math Skills", "Art Skills", "AutoCAD Experience", "Video Game Hrs/Wk"))
lineup.summary.categorical$value[lineup.summary.categorical$value=="f"] <- "Female"
lineup.summary.categorical$value[lineup.summary.categorical$value=="m"] <- "Male"
lineup.summary.categorical$value[lineup.summary.categorical$value=="y"] <- "TRUE"
lineup.summary.categorical$value[lineup.summary.categorical$value=="n"] <- "FALSE"


qplot(data=lineup.summary.categorical, x=value, y=lineup, geom="boxplot") + facet_wrap(~variable, scales="free_x") + xlab("") + ylab("Scaled Lineup Score") + theme_bw() + geom_point(aes(x=value, y=lineup), shape=1, size=3)
ggsave(paste(imgdir, "fig-VisReasoningAnalysisCat.png", sep=""), width=8, height=6)
@

<<correlations, fig.cap="Scree plot of principle component analysis of performance on the different test batteries.", out.width=".5\\linewidth", fig.height=4.5, fig.width=7.5, comment="|">>=
cor(ans.summary[,c("lineup","card_rot", "fig_class", "folding", "vis_search")])
# using scaled version right now, should be changed to unscaled once the scores are internally scaled.
pca <- prcomp(ans.summary[,c("lineup", "card_rot", "fig_class", "folding", "vis_search")], scale=T)
summary(pca)
screeplot(pca)
@

\begin{figure}[htbp]\centering
\includegraphics[width=\textwidth]{fig-VisReasoningAnalysisCts}
\caption[Visual Aptitude Study Results]{Preliminary results of continuous variables compared to lineup score.}\label{fig:visualaptitudects}
\end{figure}

\comment{\textit{I did change the lineup scoring - for some reason, I was averaging before (and I hadn't included the third battery of lineups b/c of scoring issues). That explains the scale, but not the change in art skills association.}}

In figure~\ref{fig:visualaptitudects}, we see that participant performance on lineups is positively correlated with performance on card rotation, figure classification, and paper folding tasks. This suggests that skills associated with visual reasoning ability are related to lineup performance. As participants must use the same skills in lineups (mental rotation, classification and determining categorization schemes, and multi-step spatial reasoning) as in the factor-referenced tests, this is not particularly surprising. In addition,there seems to be some positive relationship between a participant's score on the visual search task and their score on lineups: the visual search task represents a baseline of a participant's ability to find a matching pattern, while lineups require that task as well as the ability to determine what the pattern is for a particular graph. Even excluding the one low visual search score that is a high-leverage point, there seems to be a positive relationship between a participant's score on lineups and their score for visual search. 

\begin{figure}[htbp]\centering
\includegraphics[width=\textwidth]{fig-VisReasoningAnalysisCat}
\caption[Visual Aptitude Study Results]{Preliminary results of categorical variables compared to lineup score.}\label{fig:visualaptitudecat}
\end{figure}

Figure \ref{fig:visualaptitudecat} shows participants' responses to the questionnaire given at the beginning of the study; these demographic questions allow us to compare the participants in our study to the undergraduate population of Iowa State as well as to explore relationships between demographic characteristics (major, research experience, etc.) and score on various sections of this test. There is little difference in lineup performance for participants of different age, self-assessed skill rating, previous participation in math or science research or completion of a statistics class. There is a significant difference between male and female performance on lineups; this is not particularly surprising, since men perform better on many spatial tests \citep{voyer1995magnitude} and performance on spatial tests is correlated with phase of the menstrual cycle in women \citep{hausmann2000sex}. In addition, completion of Calculus I is associated with increased performance on lineups (though completion of calculus is also associated with sex). AutoCAD experience is also not significantly associated with lineup performance; there is a difference in the medians, but it does not rise to the level of significance. There is also a significant association between hours of video games played per week and score on lineups, however, this association is not monotonic and may be at least partially a result of the large difference in performance due to sex. 


<<t.test.categorical, echo=T, comment="|">>=
t.test(ans.summary$lineup[ans.summary$sex=="m"], ans.summary$lineup[ans.summary$sex=="f"])

t.test(ans.summary$lineup[ans.summary$calc_1=="y"], ans.summary$lineup[ans.summary$calc_1=="n"])

ans.summary$vidgame_hrs_factor_new <- factor(ans.summary$vidgame_hrs_factor, ordered=FALSE)
summary(lm(data=ans.summary, lineup~vidgame_hrs_factor_new))

summary(lm(data=ans.summary, lineup~sex+calc_1+vidgame_hrs_factor_new))
@

All results and data shown here are done in accordance with IRB \# 13-581.

\bibliography{references}

\section*{Appendix}
T-tests of results for Hillary and Stephanie: 
<<ttest, echo=T, include=T>>=
t.test(ans.summary$card_rot[1:18], ans.summary$card_rot[-c(1:18)])
t.test(ans.summary$folding[1:18], ans.summary$folding[-c(1:18)])
t.test(ans.summary$lineup[1:18], ans.summary$lineup[-c(1:18)])
t.test(ans.summary$vis_search[1:18], ans.summary$vis_search[-c(1:18)])
@

\end{document}